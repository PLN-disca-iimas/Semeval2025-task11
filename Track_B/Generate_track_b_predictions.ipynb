{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "L4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqMKloDjJinH"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers torch scikit-learn unidecode datasets"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Importar las librerías\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.optim import SGD, Adam, AdamW\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, AutoTokenizer,  AutoModelForSequenceClassification\n"
   ],
   "metadata": {
    "id": "R0U_zhm4JqRz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Detectar dispositivo (GPU o CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "id": "SoX7CvO0NnSB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "lang = \"ukr\"\n",
    "global_max_token_len = 71\n",
    "\n",
    "input_file = f'/content/drive/MyDrive/Proyectos/semeval/data/newest/test/{lang}.csv'\n",
    "output_file = f'/content/drive/MyDrive/Proyectos/semeval/final_predictions/pred_{lang}.csv'"
   ],
   "metadata": {
    "id": "adi-tFJvKfhu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class MultilabelModel:\n",
    "    def __init__(self, model_path):\n",
    "        # Cargar el modelo y el tokenizador\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.model.to(device)\n",
    "        self.model.eval()  # Configurar el modelo en modo de evaluación\n",
    "\n",
    "    def predict(self, text):\n",
    "        # Tokenizar el texto\n",
    "        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=global_max_token_len, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # Realizar inferencia\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            # Aplicar sigmoide para obtener probabilidades\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "        # Convertir probabilidades a etiquetas (0 o 1) con un umbral de 0.5\n",
    "        preds = (probs > 0.5).astype(int)\n",
    "\n",
    "        # Asignar los nombres de las emociones a las predicciones\n",
    "        emotions = ['anger', 'disgust' ,'fear', 'joy', 'sadness', 'surprise']\n",
    "        predictions = {emotion: int(preds[0][i]) for i, emotion in enumerate(emotions)}\n",
    "\n",
    "        return predictions\n",
    "\n"
   ],
   "metadata": {
    "id": "zAQ-vze9KJM3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class LevelModel:\n",
    "    def __init__(self, model_path):\n",
    "        # Cargar el modelo y el tokenizador\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.model.to(device)\n",
    "        self.model.eval()  # Configurar el modelo en modo de evaluación\n",
    "\n",
    "    def predict(self, text):\n",
    "        # Tokenizar el texto\n",
    "        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=global_max_token_len, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # Realizar inferencia\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            # Obtener la clase con la probabilidad más alta\n",
    "            pred_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "        return int(pred_class) +1\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "CKkaC5hxKZss"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "model_folder = f'/content/drive/MyDrive/Servicio social/Proyectos/semeval/models/{lang}/'\n",
    "\n",
    "\n",
    "multilabel_model = MultilabelModel( model_folder + \"multilabel\")\n",
    "anger_model = LevelModel( model_folder + \"anger_3_level\")\n",
    "disgust_model = LevelModel( model_folder + \"disgust_3_level\")\n",
    "fear_model = LevelModel( model_folder + \"fear_3_level\")\n",
    "joy_model = LevelModel( model_folder + \"joy_3_level\")\n",
    "sadness_model = LevelModel( model_folder + \"sadness_3_level\")\n",
    "surprise_model = LevelModel( model_folder + \"surprise_3_level\")"
   ],
   "metadata": {
    "id": "ioyGZ14qM6Kb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_complete_prediction(text):\n",
    "    predictions = multilabel_model.predict(text)\n",
    "    anger = predictions[\"anger\"]\n",
    "    disgust = predictions[\"disgust\"]\n",
    "    fear = predictions[\"fear\"]\n",
    "    joy = predictions[\"joy\"]\n",
    "    sadness = predictions[\"sadness\"]\n",
    "    surprise = predictions[\"surprise\"]\n",
    "\n",
    "    if anger != 0:\n",
    "        predictions[\"anger\"] = anger_model.predict(text)\n",
    "    if disgust != 0:\n",
    "        predictions[\"disgust\"] = disgust_model.predict(text)\n",
    "    if fear != 0:\n",
    "        predictions[\"fear\"] = fear_model.predict(text)\n",
    "    if joy != 0:\n",
    "        predictions[\"joy\"] = joy_model.predict(text)\n",
    "    if sadness != 0:\n",
    "        predictions[\"sadness\"] = sadness_model.predict(text)\n",
    "    if surprise != 0:\n",
    "        predictions[\"surprise\"] = surprise_model.predict(text)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "results = []\n",
    "for index, row in df.iterrows():\n",
    "    print(f'\\nEntering index {index}')\n",
    "    id = row[\"id\"]\n",
    "    text = row['text']\n",
    "    predictions = get_complete_prediction(text)\n",
    "    anger = predictions[\"anger\"]\n",
    "    disgust = predictions[\"disgust\"]\n",
    "    fear = predictions[\"fear\"]\n",
    "    joy = predictions[\"joy\"]\n",
    "    sadness = predictions[\"sadness\"]\n",
    "    surprise = predictions[\"surprise\"]\n",
    "    results.append([id, anger, disgust, fear, joy, sadness, surprise])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "ty9_MApGL27u"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_res = pd.DataFrame(results)\n",
    "df_res.columns = [\"id\",\"anger\", \"disgust\" ,\"fear\", \"joy\", \"sadness\",\"surprise\"]\n",
    "df_res.to_csv(output_file, index=False)"
   ],
   "metadata": {
    "id": "1kPNYMnhM0T0"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
